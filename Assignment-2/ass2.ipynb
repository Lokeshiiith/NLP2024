{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import math\n",
    "import conllu\n",
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 246,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "  device = torch.device(\"cuda\")\n",
    "else:\n",
    "  device = torch.device(\"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_to_index = {}\n",
    "tag_to_index = {}\n",
    "max_sentence_length = 0\n",
    "word_count = {}\n",
    "word_to_index['<PAD>'] = 0\n",
    "tag_to_index['<UNK>'] = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Got all senteces with padding and each sentence with pos tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This will provide each sentence with paddings <unk>\n",
    "def process_dataset(dataset_file, p=2, s=3):\n",
    "    sentences_list = []\n",
    "    pos_list = []\n",
    "\n",
    "    with open(dataset_file, 'r', encoding='utf-8') as f:\n",
    "        sentence_tokens = []\n",
    "        pos_tags = []\n",
    "\n",
    "        for line in f:\n",
    "            line = line.strip()\n",
    "\n",
    "            if line.startswith('#'):\n",
    "                sentence_tokens = []\n",
    "                pos_tags = []\n",
    "                continue\n",
    "            elif line == '':\n",
    "                # Append padding to the end of the sentence\n",
    "                padded_sentence = ' '.join(['<PAD>'] * p) + ' ' + ' '.join(sentence_tokens) + ' ' + ' '.join(['<PAD>'] * s)\n",
    "                padded_pos = ' '.join(['<UNK>'] * p + pos_tags + ['<UNK>'] * s)\n",
    "                sentences_list.append(padded_sentence)\n",
    "                pos_list.append(padded_pos)\n",
    "                continue\n",
    "            else:\n",
    "                # New sentence begins\n",
    "                token_attrs = line.split('\\t')\n",
    "                word_form = token_attrs[1]  # Word form of the token\n",
    "                pos_tag = token_attrs[3]    # POS tag of the token\n",
    "                sentence_tokens.append(word_form)\n",
    "                pos_tags.append(pos_tag)\n",
    "\n",
    "    return sentences_list, pos_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_indices(sentences_list, pos_list, word_to_index, tag_to_index, max_sentence_length, word_count):\n",
    "    # Process each sentence to tokenize the data\n",
    "    for sentence_str, tag_str in zip(sentences_list, pos_list):\n",
    "        # Tokenize the sentence into individual tokens\n",
    "        tokens = sentence_str.split(' ')\n",
    "        tags = tag_str.split(' ')\n",
    "            # Word to index\n",
    "        for word, tag in zip(tokens, tags):\n",
    "            if word not in word_to_index:\n",
    "                word_to_index[word] = len(word_to_index)\n",
    "                word_count[word] = word_count.get(word, 0) + 1\n",
    "        # Tag to index\n",
    "            if tag not in tag_to_index:\n",
    "                tag_to_index[tag] = len(tag_to_index)\n",
    "        max_sentence_length = max(max_sentence_length, len(tokens))\n",
    "    return word_to_index, tag_to_index, max_sentence_length, word_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = \"./conllu/train.conllu\"\n",
    "test_dataset = \"./conllu/test.conllu\"\n",
    "val_dataset = \"./conllu/val.conllu\"\n",
    "train_sentece_list, train_pos_list = process_dataset(train_dataset, p= 2, s= 3)\n",
    "test_sentece_list, test_pos_list = process_dataset(test_dataset, p= 2, s= 3)\n",
    "val_sentece_list, val_pos_list = process_dataset(val_dataset, p= 2, s= 3)\n",
    "\n",
    "\n",
    "sentences_list = train_sentece_list + test_sentece_list + val_sentece_list\n",
    "pos_list = train_pos_list + test_pos_list + val_pos_list\n",
    "\n",
    "# Split the data into sentences\n",
    "word_to_index = {'<UNK>': 0}\n",
    "tag_to_index = {'<UNK>': 0}\n",
    "word_count = {'<UNK>': 1}\n",
    "max_sentence_length = 0\n",
    "# get all indices\n",
    "word_to_index, tag_to_index, max_sentence_length, word_count = get_indices(sentences_list, pos_list, word_to_index, tag_to_index, max_sentence_length, word_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function for calculating embedding for all sentences "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [],
   "source": [
    "def PrepareEmbedding(sentence_dataset, pos_dataset, word_to_index, tag_to_index, max_sentence_length, word_count):\n",
    "    token_embeddings = []\n",
    "    labels_embedding = []\n",
    "    for sentence_str, tag_str in zip(sentence_dataset, pos_dataset):\n",
    "        # Tokenize the sentence into individual tokens\n",
    "        tokens = sentence_str.split(' ')\n",
    "        tags = tag_str.split(' ')\n",
    "        one_sentence_token_embedding = []\n",
    "        one_sentence_pos_embedding = []\n",
    "        # Word to index\n",
    "        for word, tag in zip(tokens, tags):\n",
    "            if word in word_to_index:\n",
    "                if word_count[word] < 2:\n",
    "                    word_cur_idx = word_to_index['<UNK>']\n",
    "                else:\n",
    "                    word_cur_idx = word_to_index[word]\n",
    "            else:\n",
    "                word_cur_idx = word_to_index['<UNK>']\n",
    "            # Tag to index\n",
    "            if tag in tag_to_index:\n",
    "                tag_cur_idx = tag_to_index[tag]\n",
    "            else:\n",
    "                tag_cur_idx = tag_to_index['<UNK>']\n",
    "            one_sentence_token_embedding.append(word_cur_idx)\n",
    "            one_sentence_pos_embedding.append(tag_cur_idx)\n",
    "        # Pad sequences using PyTorch's pad_sequence function\n",
    "        one_sentence_token_embedding.extend([0] * (max_sentence_length - len(one_sentence_token_embedding)))\n",
    "        one_sentence_pos_embedding.extend([0] * (max_sentence_length - len(one_sentence_pos_embedding)))\n",
    "        token_embeddings.append(one_sentence_token_embedding)\n",
    "        labels_embedding.append(one_sentence_pos_embedding)\n",
    "    return token_embeddings, labels_embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sentence_embeddings, train_pos_embeddings = PrepareEmbedding(train_sentece_list, train_pos_list, word_to_index, tag_to_index, max_sentence_length, word_count)\n",
    "test_sentence_embeddings, test_pos_embeddings = PrepareEmbedding(test_sentece_list, test_pos_list, word_to_index, tag_to_index, max_sentence_length, word_count)\n",
    "val_sentence_embeddings, val_pos_embeddings = PrepareEmbedding(val_sentece_list, val_pos_list, word_to_index, tag_to_index, max_sentence_length, word_count)\n",
    "# It will save a lot of time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feed Forward netword"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "# Step 1: Define the Model\n",
    "class FFNN(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, hidden_size, output_size, p, s):\n",
    "        super(FFNN, self).__init__()\n",
    "        # Calculate the actual input size considering embedding dimensions\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
    "        self.fc1 = nn.Linear((p + s + 1) *embedding_dim , hidden_size)\n",
    "        self.fc2 = nn.Linear(hidden_size, output_size)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Flatten the input tensor\n",
    "        first = self.embedding(x)\n",
    "        first = first.view(-1)\n",
    "        out = self.fc1(first)\n",
    "        out = self.relu(out)\n",
    "        out = self.fc2(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the number of steps after which to print the loss and accuracy\n",
    "print_interval = 10\n",
    "\n",
    "# Step 2: Define Loss Function\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Step 3: Instantiate Model\n",
    "vocab_size = len(word_to_index)\n",
    "embedding_dim = 100  # Example dimension, adjust as needed\n",
    "hidden_size = 128    # Example size, adjust as needed\n",
    "output_size = len(tag_to_index)\n",
    "p = 2\n",
    "s = 3\n",
    "model = FFNN(vocab_size, embedding_dim, hidden_size, output_size, p, s)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001) # Example optimizer, adjust as needed\n",
    "\n",
    "def train_model(model, criterion, optimizer, train_embeddings, train_pos_embeddings, print_interval=10):\n",
    "    model.train()  # Set the model to training mode\n",
    "    running_loss = 0.0\n",
    "\n",
    "    # Iterate over the training dataset\n",
    "    for token_indices, pos_indices in zip(train_embeddings, train_pos_embeddings):\n",
    "        # Create sliding window of size 6 and convert to tensors\n",
    "        for i in range(p, len(token_indices) - s):\n",
    "            window_tokens = token_indices[i-p:i+s+1]    \n",
    "            window_tokens_tensor = torch.LongTensor(window_tokens)\n",
    "            pos_tag = pos_indices[i]\n",
    "            # creating one hot encoding for the pos tag\n",
    "            # length should be the number of tags\n",
    "            pos_tag_tensor = torch.zeros(len(tag_to_index))\n",
    "            pos_tag_tensor[pos_tag] = 1\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(window_tokens_tensor)  # Forward pass\n",
    "            # Calculate loss\n",
    "            loss = criterion(outputs, pos_tag_tensor)  # Compare outputs with true labels\n",
    "            # Backward pass and optimization\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "\n",
    "    return running_loss / len(train_embeddings)\n",
    "\n",
    "def evaluate_model(model, criterion, val_embeddings, val_pos_embeddings):\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "    running_loss = 0.0\n",
    "\n",
    "    # Iterate over the validation dataset\n",
    "    with torch.no_grad():\n",
    "        for token_indices, pos_indices in zip(val_embeddings, val_pos_embeddings):\n",
    "            # Create sliding window of size 6 and convert to tensors\n",
    "            for i in range(p, len(token_indices) - s):\n",
    "                window_tokens = token_indices[i-p:i+s+1]    \n",
    "                window_tokens_tensor = torch.LongTensor(window_tokens)\n",
    "                pos_tag = pos_indices[i]\n",
    "                # creating one hot encoding for the pos tag\n",
    "                # length should be the number of tags\n",
    "                pos_tag_tensor = torch.zeros(len(tag_to_index))\n",
    "                pos_tag_tensor[pos_tag] = 1\n",
    "                outputs = model(window_tokens_tensor)  # Forward pass\n",
    "                # Calculate loss\n",
    "                loss = criterion(outputs, pos_tag_tensor)  # Compare outputs with true labels\n",
    "                running_loss += loss.item()\n",
    "\n",
    "    return running_loss / len(val_embeddings)\n",
    "\n",
    "def test_model(model, criterion, test_embeddings, test_pos_embeddings):\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "    running_loss = 0.0\n",
    "\n",
    "    # Iterate over the test dataset\n",
    "    with torch.no_grad():\n",
    "        for token_indices, pos_indices in zip(test_embeddings, test_pos_embeddings):\n",
    "            # Create sliding window of size 6 and convert to tensors\n",
    "            for i in range(p, len(token_indices) - s):\n",
    "                window_tokens = token_indices[i-p:i+s+1]    \n",
    "                window_tokens_tensor = torch.LongTensor(window_tokens)\n",
    "                pos_tag = pos_indices[i]\n",
    "                # creating one hot encoding for the pos tag\n",
    "                # length should be the number of tags\n",
    "                pos_tag_tensor = torch.zeros(len(tag_to_index))\n",
    "                pos_tag_tensor[pos_tag] = 1\n",
    "                outputs = model(window_tokens_tensor)  # Forward pass\n",
    "                # Calculate loss\n",
    "                loss = criterion(outputs, pos_tag_tensor)  # Compare outputs with true labels\n",
    "                running_loss += loss.item()\n",
    "\n",
    "    return running_loss / len(test_embeddings)\n",
    "\n",
    "# Number of epochs\n",
    "num_epochs = 10\n",
    "for epoch in range(num_epochs):\n",
    "    # Training phase\n",
    "    train_loss = train_model(model, criterion, optimizer, train_sentence_embeddings, train_pos_embeddings, print_interval)\n",
    "    print(f\"Epoch [{epoch + 1}/{num_epochs}], Train Loss: {train_loss:.4f}\")\n",
    "\n",
    "    # Validation phase\n",
    "    val_loss = evaluate_model(model, criterion, val_sentence_embeddings, val_pos_embeddings)\n",
    "    print(f\"Epoch [{epoch + 1}/{num_epochs}], Validation Loss: {val_loss:.4f}\")\n",
    "\n",
    "# Testing phase\n",
    "test_loss = test_model(model, criterion, test_sentence_embeddings, test_pos_embeddings)\n",
    "print(f\"Test Loss: {test_loss:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Step [21/4273], Loss: 10.9461\n",
      "Epoch [1/10], Step [11/4273], Loss: 79.7393\n",
      "Epoch [1/10], Step [21/4273], Loss: 8.2242\n",
      "Epoch [1/10], Step [11/4273], Loss: 9.8153\n",
      "Epoch [1/10], Step [21/4273], Loss: 2.9105\n",
      "Epoch [1/10], Step [21/4273], Loss: 2.1472\n",
      "Epoch [1/10], Step [11/4273], Loss: 21.5849\n",
      "Epoch [1/10], Step [11/4273], Loss: 5.2639\n",
      "Epoch [1/10], Step [11/4273], Loss: 1.8262\n",
      "Epoch [1/10], Step [11/4273], Loss: 16.7029\n",
      "Epoch [1/10], Step [11/4273], Loss: 3.7315\n",
      "Epoch [1/10], Step [11/4273], Loss: 0.5785\n",
      "Epoch [1/10], Step [11/4273], Loss: 0.0211\n",
      "Epoch [1/10], Step [11/4273], Loss: 0.9139\n",
      "Epoch [1/10], Step [11/4273], Loss: 8.1671\n",
      "Epoch [1/10], Step [11/4273], Loss: 0.0583\n",
      "Epoch [1/10], Step [11/4273], Loss: 6.8401\n",
      "Epoch [1/10], Step [11/4273], Loss: 6.9535\n",
      "Epoch [1/10], Step [11/4273], Loss: 4.6516\n",
      "Epoch [1/10], Step [11/4273], Loss: 0.0744\n",
      "Epoch [1/10], Step [11/4273], Loss: 0.6762\n",
      "Epoch [1/10], Step [11/4273], Loss: 0.1874\n",
      "Epoch [1/10], Step [31/4273], Loss: 9.0454\n",
      "Epoch [1/10], Step [21/4273], Loss: 3.0140\n",
      "Epoch [1/10], Step [11/4273], Loss: 2.4326\n",
      "Epoch [1/10], Step [11/4273], Loss: 2.3371\n",
      "Epoch [1/10], Step [11/4273], Loss: 1.0083\n",
      "Epoch [1/10], Step [11/4273], Loss: 1.5596\n",
      "Epoch [1/10], Step [21/4273], Loss: 2.8984\n",
      "Epoch [1/10], Step [11/4273], Loss: 13.8794\n",
      "Epoch [1/10], Step [11/4273], Loss: 2.9689\n",
      "Epoch [1/10], Step [11/4273], Loss: 0.5597\n",
      "Epoch [1/10], Step [11/4273], Loss: 0.1541\n",
      "Epoch [1/10], Step [11/4273], Loss: 5.3820\n",
      "Epoch [1/10], Step [21/4273], Loss: 4.7699\n",
      "Epoch [1/10], Step [11/4273], Loss: 11.1185\n",
      "Epoch [1/10], Step [11/4273], Loss: 0.5463\n",
      "Epoch [1/10], Step [11/4273], Loss: 3.6035\n",
      "Epoch [1/10], Step [11/4273], Loss: 1.0473\n",
      "Epoch [1/10], Step [21/4273], Loss: 6.7970\n",
      "Epoch [1/10], Step [21/4273], Loss: 2.0901\n",
      "Epoch [1/10], Step [11/4273], Loss: 11.8234\n",
      "Epoch [1/10], Step [21/4273], Loss: 2.8608\n",
      "Epoch [1/10], Step [11/4273], Loss: 0.1585\n",
      "Epoch [1/10], Step [11/4273], Loss: 0.9857\n",
      "Epoch [1/10], Step [11/4273], Loss: 4.5239\n",
      "Epoch [1/10], Step [11/4273], Loss: 0.4863\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[222], line 37\u001b[0m\n\u001b[0;32m     35\u001b[0m pos_tag_tensor \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mzeros(\u001b[38;5;28mlen\u001b[39m(tag_to_index))\n\u001b[0;32m     36\u001b[0m pos_tag_tensor[pos_tag] \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m---> 37\u001b[0m \u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mzero_grad\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     38\u001b[0m outputs \u001b[38;5;241m=\u001b[39m model(window_tokens_tensor)  \u001b[38;5;66;03m# Forward pass\u001b[39;00m\n\u001b[0;32m     39\u001b[0m predicted \u001b[38;5;241m=\u001b[39m outputs\u001b[38;5;241m.\u001b[39margmax() \u001b[38;5;66;03m# Get the index of the max logit as the predicted class\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Lokes\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\optim\\optimizer.py:456\u001b[0m, in \u001b[0;36mOptimizer.zero_grad\u001b[1;34m(self, set_to_none)\u001b[0m\n\u001b[0;32m    454\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m foreach:\n\u001b[0;32m    455\u001b[0m     per_device_and_dtype_grads \u001b[38;5;241m=\u001b[39m defaultdict(\u001b[38;5;28;01mlambda\u001b[39;00m: defaultdict(\u001b[38;5;28mlist\u001b[39m))\n\u001b[1;32m--> 456\u001b[0m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mwith\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprofiler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrecord_function\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_zero_grad_profile_name\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[0;32m    457\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparam_groups\u001b[49m\u001b[43m:\u001b[49m\n\u001b[0;32m    458\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mp\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mparams\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m:\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Lokes\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\autograd\\profiler.py:492\u001b[0m, in \u001b[0;36mrecord_function.__enter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    491\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__enter__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m--> 492\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrecord \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprofiler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_record_function_enter_new\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    493\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\Lokes\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\_ops.py:502\u001b[0m, in \u001b[0;36mOpOverloadPacket.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    497\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m    498\u001b[0m     \u001b[38;5;66;03m# overloading __call__ to ensure torch.ops.foo.bar()\u001b[39;00m\n\u001b[0;32m    499\u001b[0m     \u001b[38;5;66;03m# is still callable from JIT\u001b[39;00m\n\u001b[0;32m    500\u001b[0m     \u001b[38;5;66;03m# We save the function ptr as the `op` attribute on\u001b[39;00m\n\u001b[0;32m    501\u001b[0m     \u001b[38;5;66;03m# OpOverloadPacket to access it here.\u001b[39;00m\n\u001b[1;32m--> 502\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_op\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Define the number of steps after which to print the loss and accuracy\n",
    "print_interval = 10\n",
    "running_loss = 0.0\n",
    "running_accuracy = 0.0\n",
    "# Step 2: Define Loss Function\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Step 3: Instantiate Model\n",
    "vocab_size = len(word_to_index)\n",
    "embedding_dim = 100  # Example dimension, adjust as needed\n",
    "hidden_size = 128    # Example size, adjust as needed\n",
    "output_size = len(tag_to_index)\n",
    "p = 2\n",
    "s = 3\n",
    "model = FFNN(vocab_size, embedding_dim, hidden_size, output_size, p, s)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001) # Example optimizer, adjust as needed\n",
    "num_epochs = 10 \n",
    "for epoch in range(num_epochs):\n",
    "    model.train()  # Set the model to training mode\n",
    "    running_loss = 0.0\n",
    "\n",
    "    # Iterate over your dataset\n",
    "    for sentence, pos_tags in zip(sentences_list, pos_list):\n",
    "        # Convert tokens and POS tags to indices\n",
    "        token_indices = [word_to_index[token] for token in sentence.strip().split()]\n",
    "        pos_indices = [tag_to_index[pos_tag] for pos_tag in pos_tags.strip().split()]\n",
    "        \n",
    "        # Create sliding window of size 6 and convert to tensors\n",
    "        for i in range(p, len(token_indices) - s):\n",
    "            window_tokens = token_indices[i-p:i+s+1]    \n",
    "            window_tokens_tensor = torch.LongTensor(window_tokens)\n",
    "            pos_tag = pos_indices[i]\n",
    "            # creating on e hot encodeing for the pos tag\n",
    "            # length should be the number of tags\n",
    "            pos_tag_tensor = torch.zeros(len(tag_to_index))\n",
    "            pos_tag_tensor[pos_tag] = 1\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(window_tokens_tensor)  # Forward pass\n",
    "            predicted = outputs.argmax() # Get the index of the max logit as the predicted class\n",
    "            # Calculate loss\n",
    "            loss = criterion(outputs, pos_tag_tensor)  # Compare outputs with true labels\n",
    "            # Backward pass and optimization\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "\n",
    "        # Print loss and accuracy every `print_interval` steps\n",
    "        if i % print_interval == 0:\n",
    "            print(f'Epoch [{epoch + 1}/{num_epochs}], Step [{i + 1}/{len(sentences_list)}], Loss: {running_loss / print_interval:.4f}')\n",
    "            running_loss = 0.0\n",
    "          "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data prepare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = process_data(train_data, word_to_index, tag_to_index, max_sentence_length, word_count)\n",
    "X_val, y_val = process_data(val_data, word_to_index, tag_to_index, max_sentence_length, word_count)\n",
    "X_test, y_test = process_data(test_data, word_to_index, tag_to_index, max_sentence_length, word_count)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 2: Create PyTorch DataLoaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import TensorDataset, DataLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create PyTorch datasets and data loaders for training data. This allows efficient batching and shuffling of data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = TensorDataset(torch.from_numpy(X_train), torch.from_numpy(y_train))\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "X_train.shape[1] is used to specify the input size of the neural network model.     X_train.shape[1] accesses the second element of the shape tuple, which represents the number of features or input dimensions in your dataset. In the example (1000, 50), X_train.shape[1] would be 50.\n",
    "\n",
    "Sending X_train.shape[1] as the input_size parameter to the FFNN constructor ensures that the input layer of your neural network has the correct number of neurons to accommodate the input features of your dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Define Loss Function and Optimizer\n",
    "model = FFNN(input_size=X_train.shape[1], hidden_size=128, output_size=y_train.shape[1])\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Step 4: Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/20], Loss: 1942.5025033523787\n",
      "Epoch [2/20], Loss: 1406.451219245569\n",
      "Epoch [3/20], Loss: 1080.4993978471898\n",
      "Epoch [4/20], Loss: 874.9364979302705\n",
      "Epoch [5/20], Loss: 744.392890588561\n",
      "Epoch [6/20], Loss: 654.735463156629\n",
      "Epoch [7/20], Loss: 589.1151683294951\n",
      "Epoch [8/20], Loss: 538.1906392111707\n",
      "Epoch [9/20], Loss: 498.44278773976794\n",
      "Epoch [10/20], Loss: 465.6859440590019\n",
      "Epoch [11/20], Loss: 438.57284591447063\n",
      "Epoch [12/20], Loss: 415.38864682325675\n",
      "Epoch [13/20], Loss: 395.12138571668027\n",
      "Epoch [14/20], Loss: 377.8649383089436\n",
      "Epoch [15/20], Loss: 362.8608712723006\n",
      "Epoch [16/20], Loss: 348.303059819919\n",
      "Epoch [17/20], Loss: 335.64912983908584\n",
      "Epoch [18/20], Loss: 324.2286862045971\n",
      "Epoch [19/20], Loss: 313.86049435743644\n",
      "Epoch [20/20], Loss: 303.9825999701201\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 20\n",
    "# for training \n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for inputs, labels in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs.float())\n",
    "        loss = criterion(outputs, labels.float())\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "    print(f\"Epoch [{epoch + 1}/{num_epochs}], Loss: {running_loss / len(train_loader)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(1000):  # Adjust number of epochs as needed\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = criterion(output, target.float())\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if batch_idx % 100 == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "                100. * batch_idx / len(train_loader), loss.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_to_tag = {v: k for k, v in tag_to_index.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 1 7 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "  0 0 0 0 0 0 0 0 0 0]]\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'numpy.ndarray' object has no attribute 'to'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[105], line 33\u001b[0m\n\u001b[0;32m     31\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m     32\u001b[0m     model\u001b[38;5;241m.\u001b[39meval()  \u001b[38;5;66;03m# Set model to evaluation mode\u001b[39;00m\n\u001b[1;32m---> 33\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_sequence\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     35\u001b[0m \u001b[38;5;66;03m# Map output predictions to POS tags\u001b[39;00m\n\u001b[0;32m     36\u001b[0m predicted_tags \u001b[38;5;241m=\u001b[39m [index_to_tag[torch\u001b[38;5;241m.\u001b[39margmax(output)\u001b[38;5;241m.\u001b[39mitem()] \u001b[38;5;28;01mfor\u001b[39;00m output \u001b[38;5;129;01min\u001b[39;00m outputs]\n",
      "File \u001b[1;32mc:\\Users\\Lokes\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "Cell \u001b[1;32mIn[71], line 11\u001b[0m, in \u001b[0;36mFFNN.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[0;32m     10\u001b[0m     \u001b[38;5;66;03m# Ensure input tensor has the same data type as the weight matrices\u001b[39;00m\n\u001b[1;32m---> 11\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[43mx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfc1\u001b[38;5;241m.\u001b[39mweight\u001b[38;5;241m.\u001b[39mdtype)\n\u001b[0;32m     12\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfc1(x)\n\u001b[0;32m     13\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrelu(x)\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'to'"
     ]
    }
   ],
   "source": [
    "# Example input sentence\n",
    "input_sentence = \"Mary had a little lamb\"\n",
    "# Tokenize the sentence and convert it to a sequence of word indices\n",
    "words = sentence.split()\n",
    "input_sequence = []\n",
    "for word in words:\n",
    "    if word in word_to_index:\n",
    "        if word_count[word] < 2:\n",
    "            input_sequence.append(word_to_index['<UNK>'])\n",
    "        else:\n",
    "            input_sequence.append(word_to_index[word])\n",
    "    else:\n",
    "        input_sequence.append(word_to_index['<UNK>'])\n",
    "\n",
    "# Tokenize the input sentence\n",
    "# input_sequence = input_sentence.split()\n",
    "# Pad the sequence with zeros to make it the same length as max_sen_len\n",
    "if len(input_sequence) < max_sentence_length:\n",
    "    input_sequence += [0] * (max_sentence_length - len(input_sequence))\n",
    "\n",
    "# Convert tokens to indices using the vocabulary\n",
    "input_indices = [word_to_index.get(token, word_to_index['<UNK>']) for token in input_sequence]\n",
    "# Pad the input sequence if necessary\n",
    "input_sequence = np.array(input_sequence).reshape(1, max_sentence_length)\n",
    "print(input_sequence)\n",
    "# Convert input indices to PyTorch tensor\n",
    "# input_tensor = torch.tensor(input_sequence)\n",
    "# Ensure input tensor has the correct shape and type if needed\n",
    "\n",
    "# Pass the input through the model\n",
    "with torch.no_grad():\n",
    "    model.eval()  # Set model to evaluation mode\n",
    "    outputs = model(input_sequence)\n",
    "\n",
    "# Map output predictions to POS tags\n",
    "predicted_tags = [index_to_tag[torch.argmax(output).item()] for output in outputs]\n",
    "\n",
    "print(\"Input sentence:\", input_sentence)\n",
    "print(\"Predicted tags:\", predicted_tags)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question2 : 2 Recurrent Neural Network POS Tagging\n",
    "Design and implement a model which uses Recurrent Neural Networks (Vanilla\n",
    "RNN, LSTM, or GRU) for POS Tagging. The model should take the embed\u0002dings for all tokens in a sentence and output the corresponding POS tags in\n",
    "sequence.\n",
    "- For Example: In the sentence \"An apple a day keeps the doctor away\",\n",
    " the model takes the embeddings for \n",
    "- [\"An\", \"apple\", \"a\", \"day\", \"keeps\", \"the\",\"doctor\", \"away\"] and\n",
    " outputs the POS tags for all the words in the sentence\n",
    "- [\"DET\", \"NOUN\", \"DET\", \"NOUN\", \"VERB\", \"DET\", \"NOUN\", \"ADV\"] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step1 : Count all words and postags and provide them a index value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Doing it for all 3 datasets train, validation and test-dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./conllu/train.conllu\", \"r\", encoding=\"utf-8\") as f:\n",
    "    train_data = f.read()\n",
    "with open(\"./conllu/val.conllu\", \"r\", encoding=\"utf-8\") as f:\n",
    "    val_data = f.read()\n",
    "with open(\"./conllu/test.conllu\", \"r\", encoding=\"utf-8\") as f:\n",
    "    test_data = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_dataset(dataset_file, p=2, s=3):\n",
    "    sentences_list = []\n",
    "    pos_list = []\n",
    "\n",
    "    with open(dataset_file, 'r') as f:\n",
    "        sentence_tokens = []\n",
    "        pos_tags = []\n",
    "\n",
    "        for line in f:\n",
    "            line = line.strip()\n",
    "\n",
    "            if line.startswith('#'):\n",
    "                sentence_tokens = []\n",
    "                pos_tags = []\n",
    "                continue\n",
    "            elif line == '':\n",
    "                # Append padding to the end of the sentence\n",
    "                padded_sentence = ' '.join(['<PAD>'] * p) + ' ' + ' '.join(sentence_tokens) + ' ' + ' '.join(['<PAD>'] * s)\n",
    "                padded_pos = ' '.join(['<UNK>'] * p + pos_tags + ['<UNK>'] * s)\n",
    "                sentences_list.append(padded_sentence)\n",
    "                pos_list.append(padded_pos)\n",
    "                continue\n",
    "            else:\n",
    "                # New sentence begins\n",
    "                token_attrs = line.split('\\t')\n",
    "                word_form = token_attrs[1]  # Word form of the token\n",
    "                pos_tag = token_attrs[3]    # POS tag of the token\n",
    "                sentence_tokens.append(word_form)\n",
    "                pos_tags.append(pos_tag)\n",
    "\n",
    "    return sentences_list, pos_list\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### for all train, test and validation dataset\n",
    "- I got all sentences tokens and respective pos-tag in form of sentence sepateted by space \n",
    "- Max sentece length, word count , word to index adn tag t index "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into sentences\n",
    "word_to_index = {'<PAD>': 0, '<UNK>': 1}\n",
    "tag_to_index = {'<PAD>': 0, '<UNK>': 1}\n",
    "word_count = {'<PAD>': 1, '<UNK>': 1}\n",
    "max_sentence_length = 0\n",
    "train_dataset = \"./conllu/train.conllu\"\n",
    "test_dataset = \"./conllu/test.conllu\"\n",
    "val_dataset = \"./conllu/val.conllu\"\n",
    "train_sentece_list, train_pos_list = process_dataset(train_dataset, p= 2, s= 3)\n",
    "test_sentece_list, test_pos_list = process_dataset(test_dataset, p= 2, s= 3)\n",
    "val_sentece_list, val_pos_list = process_dataset(val_dataset, p= 2, s= 3)\n",
    "\n",
    "sentences_list = train_sentece_list + test_sentece_list + val_sentece_list\n",
    "pos_list = train_pos_list + test_pos_list + val_pos_list\n",
    "\n",
    "# Process each sentence to tokenize the data\n",
    "for sentence_str, tag_str in zip(sentences_list, pos_list):\n",
    "    # Tokenize the sentence into individual tokens\n",
    "    tokens = sentence_str.split(' ')\n",
    "    tags = tag_str.split(' ')\n",
    "        # Word to index\n",
    "    for word, tag in zip(tokens, tags):\n",
    "        if word not in word_to_index:\n",
    "            word_to_index[word] = len(word_to_index)\n",
    "            word_count[word] = word_count.get(word, 0) + 1\n",
    "    # Tag to index\n",
    "        if tag not in tag_to_index:\n",
    "            tag_to_index[tag] = len(tag_to_index)\n",
    "    max_sentence_length = max(max_sentence_length, len(tokens))\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"out.txt\", \"w\") as f:\n",
    "    for word in tag_to_index:\n",
    "        f.write(f\"{word}\\n\")    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PAdding and provide tag <unk> to those words wshich comes once"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- train_sentece_list, train_pos_list  \n",
    "- test_sentece_list, test_pos_list \n",
    "- val_sentece_list, val_pos_list  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GET EMBEDDINGS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Change to embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "def PrepareEmbedding(sentence_dataset, pos_dataset, word_to_index, tag_to_index, max_sentence_length, word_count):\n",
    "    token_embeddings = []\n",
    "    labels_embedding = []\n",
    "    for sentence_str, tag_str in zip(sentence_dataset, pos_dataset):\n",
    "        # Tokenize the sentence into individual tokens\n",
    "        tokens = sentence_str.split(' ')\n",
    "        tags = tag_str.split(' ')\n",
    "        one_sentence_token_embedding = []\n",
    "        one_sentence_pos_embedding = []\n",
    "        # Word to index\n",
    "        for word, tag in zip(tokens, tags):\n",
    "            if word in word_to_index:\n",
    "                if word_count[word] < 2:\n",
    "                    word_cur_idx = word_to_index['<UNK>']\n",
    "                else:\n",
    "                    word_cur_idx = word_to_index[word]\n",
    "            else:\n",
    "                word_cur_idx = word_to_index['<UNK>']\n",
    "            # Tag to index\n",
    "            if tag in tag_to_index:\n",
    "                tag_cur_idx = tag_to_index[tag]\n",
    "            else:\n",
    "                tag_cur_idx = tag_to_index['<UNK>']\n",
    "            one_sentence_token_embedding.append(word_cur_idx)\n",
    "            one_sentence_pos_embedding.append(tag_cur_idx)\n",
    "        # Pad sequences using PyTorch's pad_sequence function\n",
    "        one_sentence_token_embedding.extend([0] * (max_sentence_length - len(one_sentence_token_embedding)))\n",
    "        one_sentence_pos_embedding.extend([0] * (max_sentence_length - len(one_sentence_pos_embedding)))\n",
    "        token_embeddings.append(one_sentence_token_embedding)\n",
    "        labels_embedding.append(one_sentence_pos_embedding)\n",
    "    return token_embeddings, labels_embedding\n",
    "            \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sentece_embeddings, train_pos_embeddings = PrepareEmbedding(train_sentece_list, train_pos_list, word_to_index, tag_to_index, max_sentence_length, word_count)\n",
    "test_sentece_embeddings, test_pos_embeddings = PrepareEmbedding(test_sentece_list, test_pos_list, word_to_index, tag_to_index, max_sentence_length, word_count)\n",
    "val_sentece_embeddings, val_pos_embeddings = PrepareEmbedding(val_sentece_list, val_pos_list, word_to_index, tag_to_index, max_sentence_length, word_count)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# index to tag dictionary will be used for predicting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: '<PAD>',\n",
       " 1: '<UNK>',\n",
       " 2: 'PRON',\n",
       " 3: 'AUX',\n",
       " 4: 'DET',\n",
       " 5: 'NOUN',\n",
       " 6: 'ADP',\n",
       " 7: 'PROPN',\n",
       " 8: 'VERB',\n",
       " 9: 'NUM',\n",
       " 10: 'ADJ',\n",
       " 11: 'CCONJ',\n",
       " 12: 'ADV',\n",
       " 13: 'PART',\n",
       " 14: 'INTJ',\n",
       " 15: 'SYM'}"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index_to_tag = {v: k for k, v in tag_to_index.items()}\n",
    "index_to_tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "51\n"
     ]
    }
   ],
   "source": [
    "with open(\"out.txt\", \"w\") as f:\n",
    "    for word in train_sentece_embeddings:\n",
    "        f.write(f\"{word}\\n\")\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lstm for training as well as validting and testing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class LSTMTagger(nn.Module):\n",
    "\n",
    "    def __init__(self, embedding_dim, hidden_dim, vocab_size, tagset_size):\n",
    "        super(LSTMTagger, self).__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.word_embeddings = nn.Embedding(vocab_size, embedding_dim)\n",
    "        self.lstm = nn.LSTM(embedding_dim, hidden_dim, bidirectional=True)\n",
    "        self.hidden2tag = nn.Linear(hidden_dim * 2, tagset_size)\n",
    "\n",
    "    def forward(self, input_sentence):\n",
    "        embeds = self.word_embeddings(input_sentence)\n",
    "        lstm_out, _ = self.lstm(embeds.view(len(input_sentence), 1, -1))\n",
    "        tag_space = self.hidden2tag(lstm_out.view(len(input_sentence), -1))\n",
    "        tag_scores = F.log_softmax(tag_space, dim=1)\n",
    "        return tag_scores\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
