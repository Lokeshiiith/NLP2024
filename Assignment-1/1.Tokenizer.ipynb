{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "1) Input: \"In 'Pride and Prejudice' by Jane Austen, Elizabeth Bennett meets Mr Darcy at a ball hosted by her friend @charles_bingly. They dance, but Mr Darcy finds her behaviour \"tolerable, but not handsome enough to tempt him\" #rude. She later visits Pemberley, Mr Darcy's estate, where she learns more about his character. Check out more information at https://janeausten.co.uk.\"\n",
    "\n",
    "Output: List of Lists [[List of tokenized words of sentence 1] , [List of tokenized words of sentence 2] ...]\n",
    "\n",
    "Example : [[\"In\", \"'\", \"Pride\", \"and\", \"Prejudice\", \"'\", \"by\", \"Jane\", \"Austen\", ',', 'Elizabeth', 'Bennett', 'meets', 'Mr', 'Darcy', 'at', 'a', 'ball', 'hosted', 'by', 'her', 'friend', '<MENTION>', '.'] , [ 'They', 'dance', ',', 'but', 'Mr', 'Darcy', 'finds', 'her', 'behavior', '\"', 'tolerable', ',', 'but', 'not', 'handsome', 'enough', 'to', 'tempt', 'him', '\"', '<HASHTAG>', '.'] , [ 'She', 'later', 'visits', 'Pemberley', ',', 'Mr', 'Darcy', \"'s\", 'estate', ',', 'where', 'she', 'learns', 'more', 'about', 'his', 'character', '.'] , ['Check', 'out', 'more', 'information', 'at', '<URL>', '.']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenizer --> sentence\n",
    "- Problem using direct split in (.) : splitting on abbreviations like \"e.g.\" or \"Mr.\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Tokenizer to handle following cases:\n",
    "# (a) Sentence Tokenizer: Divides text into sentences.\n",
    "# (b) Word Tokenizer: Splits sentences into individual words.\n",
    "# (c) Numbers: Identifies numerical values.\n",
    "# (d) Mail IDs: Recognizes email addresses.\n",
    "# (e) Punctuation: Detects punctuation marks.\n",
    "# (f) URLs: Identifies website links.\n",
    "# (g) Hashtags (#omg): Recognizes social media hashtags.\n",
    "# (h) Mentions (@john): Recognizes social media mentions.\n",
    "# 2. For the following cases, replace the tokens with appropriate placebolders:\n",
    "# (a) URLS: <URL>\n",
    "# (b) Hashtags: <HASHTA\n",
    "# (c) Mentions: <MENTION>\n",
    "# (d) Numbers: <NUM>\n",
    "# (e) Mail IDs: <MAILID>\n",
    "# sendtnce including all above things\n",
    "sentence = '''Hi, I am Lokesh, email id is lokeshsharma123456@gmail.com. My rollnumber is 2022201041. Mywebsite is www.abc.co.in. I\n",
    "            am using #python. My twitter id is @lokeshsharma.'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def tokenize(text):\n",
    "    url_pattern1 = \"(http|ftp|https):\\/\\/([\\w_-]+(?:(?:\\.[\\w_-]+)+))([\\w.,@?^=%&:\\/~+#-]*[\\w@?^=%&\\/~+#-])\"\n",
    "    url_pattern2 = r'www\\.[^\\s\\.]+(?:\\.[^\\s\\.]+)*(?:[\\s\\.]|$)'\n",
    "    email_pattern = r'\\b[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\\.[A-Z|a-z]{2,}\\b'\n",
    "    mention_pattern = \"@\\w+\"\n",
    "    hastag_pattern = \"#[a-z0-9_]+\"\n",
    "    normal_pattern = \"[a-zA-Z]+\"\n",
    "    number_pattern = \"[0-9]+\"\n",
    "    tokens = []\n",
    "    text = text.lower()\n",
    "    text = re.sub(url_pattern1, '<URL> ', text)\n",
    "    text = re.sub(url_pattern2, '<URL> ', text)\n",
    "    text = re.sub(email_pattern, '<MAILID> ', text)\n",
    "    text = re.sub(hastag_pattern, '<HASHTAG> ', text)\n",
    "    text = re.sub(mention_pattern, '<MENTION> ', text)\n",
    "    text = re.sub(number_pattern, '<NUM> ', text)\n",
    "    tokens = re.findall(r'\\b\\w+|[^\\s\\w<>]+|<\\w+>', text)\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sentence tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Hi, I am Lokesh, email id is lokeshsharma123456@gmail.com.',\n",
       " 'My rollnumber is 2022201041.',\n",
       " 'Mywebsite is www.abc.co.in.',\n",
       " 'I\\n            am using #python.',\n",
       " 'My twitter id is @lokeshsharma.']"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pattern = \"(?<!\\w\\.\\w.)(?<![A-Z][a-z]\\.)(?<=\\.|\\?)\\s\"\n",
    "tokens = re.split(pattern, sentence)\n",
    "tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# converting each sentence into word tokens\n",
    "for i in range(len(tokens)):\n",
    "    tokens[i] = tokenize(tokens[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['hi', ',', 'i', 'am', 'lokesh', ',', 'email', 'id', 'is', '<MAILID>', '.'],\n",
       " ['my', 'rollnumber', 'is', '<NUM>', '.'],\n",
       " ['mywebsite', 'is', '<URL>'],\n",
       " ['i', 'am', 'using', '<HASHTAG>', '.'],\n",
       " ['my', 'twitter', 'id', 'is', '<MENTION>', '.']]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
